{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a logistic regression model to predict TP53 mutation from gene expression data in TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from dask_searchcv import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "\n",
    "from utils import get_model_coefficients, get_genes_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes: ['7157']\n",
      "Diseases: []\n"
     ]
    }
   ],
   "source": [
    "# We're going to be building a classifier with multiple genes filtered by two diseases \n",
    "# Example:\n",
    "# gene_ids = ['7157', '7158', '7159', '7161']\n",
    "\n",
    "# Information passed into the notebook is stored in environment variables\n",
    "gene_ids = os.environ.get('gene_ids')\n",
    "if not gene_ids:\n",
    "    gene_ids = ['7157'] # TP53 is the default\n",
    "else:\n",
    "    gene_ids = gene_ids.split('-')\n",
    "    \n",
    "disease_acronyms = os.environ.get('disease_acronyms')\n",
    "\n",
    "if not disease_acronyms:\n",
    "    disease_acronyms = [] # use all of the diseases as default\n",
    "    # disease_acronyms = ['LUAD', 'BLCA']\n",
    "else:\n",
    "    disease_acronyms = disease_acronyms.split('-')\n",
    "    \n",
    "print(\"Genes: \" + str(gene_ids))\n",
    "print(\"Diseases: \" + str(disease_acronyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here is some [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) regarding the classifier and hyperparameters*\n",
    "\n",
    "*Here is some [information](https://ghr.nlm.nih.gov/gene/TP53) about TP53*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('download', 'expression-matrix.tsv.bz2')\n",
    "expression_df = pd.read_table(path, index_col=0)\n",
    "\n",
    "path = os.path.join('download', 'mutation-matrix.tsv.bz2')\n",
    "mutation_df = pd.read_table(path, index_col=0)\n",
    "\n",
    "path = os.path.join('download', 'covariates.tsv')\n",
    "covariate_df = pd.read_table(path, index_col=0)\n",
    "\n",
    "path = os.path.join('download', 'expression-genes.tsv')\n",
    "expression_genes_df = pd.read_table(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select acronym_x and n_mutations_log1p covariates only\n",
    "disease_cols = [col for col in covariate_df.columns if col.startswith('acronym_')]\n",
    "\n",
    "# Filter covariate columns by disease if a list was provided\n",
    "if disease_acronyms:\n",
    "    disease_cols = [col for col in disease_cols if col.endswith(tuple(disease_acronyms))]\n",
    "    \n",
    "selected_cols = disease_cols + ['n_mutations_log1p']\n",
    "covariate_df = covariate_df[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter the rows by disease type\n",
    "# subsection of columns with row-wise max\n",
    "has_disease = covariate_df[disease_cols].max(axis=1) > 0\n",
    "covariate_df = covariate_df[has_disease]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter by sample_id\n",
    "expression_df = expression_df[expression_df.index.isin(covariate_df.index)]\n",
    "\n",
    "# filter by sample_id\n",
    "mutation_df = mutation_df[mutation_df.index.isin(covariate_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The series holds Gene Mutation Status for each sample\n",
    "# Take max of mutation status, meaning if any of the genes mutated the value should be 1\n",
    "y = mutation_df[gene_ids].max(axis=1)\n",
    "y.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Gene expression matrix shape: {}'.format(expression_df.shape))\n",
    "print('Covariates matrix shape: {}'.format(covariate_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set aside 10% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Typically, this type of split can only be done \n",
    "# for genes where the number of mutations is large enough\n",
    "X = pd.concat([covariate_df, expression_df], axis='columns')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Here are the percentage of tumors with TP53\n",
    "y.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_feature_set_columns(X, feature_set):\n",
    "    \"\"\"\n",
    "    Select the feature set for the different models within the pipeline\n",
    "    \"\"\"\n",
    "    n_covariates = len(covariate_df.columns)\n",
    "    if feature_set == 'covariates':\n",
    "        return X[:, :n_covariates]\n",
    "    if feature_set == 'expressions':\n",
    "        return X[:, n_covariates:]\n",
    "    raise ValueError('feature_set not supported: {}'.format(feature_set))\n",
    "\n",
    "# Creates the expression features by standarizing them and running PCA\n",
    "# Because the expressions matrix is so large, we preprocess with PCA\n",
    "# The amount of variance in the data captured by ~100 components is high\n",
    "expression_features = Pipeline([\n",
    "    ('select_features', FunctionTransformer(select_feature_set_columns,\n",
    "        kw_args={'feature_set': 'expressions'})),\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('pca', PCA())\n",
    "])\n",
    "\n",
    "# Creates the covariate features by selecting and standardizing them\n",
    "covariate_features = Pipeline([\n",
    "    ('select_features', FunctionTransformer(select_feature_set_columns,\n",
    "        kw_args={'feature_set': 'covariates'})),\n",
    "    ('standardize', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net classifier and model paraemeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter Sweep for Hyperparameters\n",
    "n_components_list = [50, 100]\n",
    "regularization_alpha_list = [10 ** x for x in range(-3, 1)]\n",
    "regularization_l1_ratio = 0.15\n",
    "\n",
    "param_grids = {\n",
    "    'full': {\n",
    "        'features__expressions__pca__n_components' : n_components_list,\n",
    "        'classify__alpha': regularization_alpha_list\n",
    "    },\n",
    "    'expressions': {\n",
    "        'features__expressions__pca__n_components' : n_components_list,\n",
    "        'classify__alpha': regularization_alpha_list\n",
    "    },\n",
    "    'covariates': {\n",
    "        'classify__alpha': regularization_alpha_list\n",
    "    }\n",
    "}\n",
    "\n",
    "# Classifier: Elastic Net\n",
    "classifier = SGDClassifier(penalty='elasticnet',\n",
    "                           l1_ratio=regularization_l1_ratio,\n",
    "                           loss='log', \n",
    "                           class_weight='balanced',\n",
    "                           random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full model pipelines\n",
    "pipeline_definitions = {\n",
    "    'full': Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('expressions', expression_features),\n",
    "            ('covariates', covariate_features)\n",
    "        ])),\n",
    "        ('classify', classifier)\n",
    "    ]),\n",
    "    'expressions': Pipeline([\n",
    "        ('features', FeatureUnion([('expressions', expression_features)])),\n",
    "        ('classify', classifier)\n",
    "    ]),\n",
    "    'covariates': Pipeline([\n",
    "        ('features', FeatureUnion([('covariates', covariate_features)])),\n",
    "        ('classify', classifier)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Construct cross-validated grid searches\n",
    "cv_pipelines = dict()\n",
    "for model, pipeline in pipeline_definitions.items():\n",
    "    cv = StratifiedKFold(n_splits=3, random_state=0)\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grids[model],\n",
    "        cv=cv,\n",
    "        n_jobs=1, \n",
    "        scoring='roc_auc',\n",
    "    )\n",
    "    cv_pipelines[model] = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the models\n",
    "for model, pipeline in cv_pipelines.items():\n",
    "    print('Fitting CV for model: {0}'.format(model))\n",
    "    start_time = time.perf_counter()\n",
    "    pipeline.fit(X=X_train, y=y_train)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed = datetime.timedelta(seconds=end_time - start_time)\n",
    "    print('\\truntime: {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best Parameters\n",
    "for model, pipeline in cv_pipelines.items():\n",
    "    print('#', model)\n",
    "    print(pipeline.best_params_)\n",
    "    print('cv_auroc = {:.3%}'.format(pipeline.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize hyperparameters performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame()\n",
    "for model, pipeline in cv_pipelines.items():\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(pipeline.cv_results_),\n",
    "        pd.DataFrame.from_records(pipeline.cv_results_['params'])\n",
    "    ], axis='columns')\n",
    "    df['feature_set'] = model\n",
    "    cv_results_df = cv_results_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validated performance heatmap\n",
    "cv_results_df['classify__alpha'] = cv_results_df['classify__alpha'].astype(str)\n",
    "\n",
    "(ggplot(cv_results_df, aes(x='classify__alpha',\n",
    "                           y='mean_test_score',\n",
    "                           fill='feature_set'))\n",
    " + geom_bar(stat='identity', position='dodge')\n",
    " + labs(x='Regularization strength multiplier (alpha)',\n",
    "        y='CV AUROC')\n",
    " + guides(fill=guide_legend(title=\"Feature Set\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use optimal hyperparameters to output ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_dict = {\n",
    "    model: {\n",
    "        'train': pipeline.decision_function(X_train),\n",
    "        'test':  pipeline.decision_function(X_test)\n",
    "    } for model, pipeline in cv_pipelines.items()\n",
    "}\n",
    "\n",
    "def get_threshold_metrics(y_true, y_pred):\n",
    "    roc_columns = ['fpr', 'tpr', 'threshold']\n",
    "    roc_items = zip(roc_columns, roc_curve(y_true, y_pred))\n",
    "    roc_df = pd.DataFrame.from_items(roc_items)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    return {'auroc': auroc, 'roc_df': roc_df}\n",
    "\n",
    "metrics_dict = {    \n",
    "    model: {\n",
    "        'train': get_threshold_metrics(y_train, y_pred_dict[model]['train']),\n",
    "        'test':  get_threshold_metrics(y_test, y_pred_dict[model]['test'])\n",
    "    } for model in y_pred_dict.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assemble the data for ROC curves\n",
    "model_order = ['full', 'expressions', 'covariates']\n",
    "\n",
    "auc_output = pd.DataFrame()\n",
    "roc_output = pd.DataFrame()\n",
    "\n",
    "for model in model_order:\n",
    "    metrics_partition = metrics_dict[model]\n",
    "    for partition, metrics in metrics_partition.items():\n",
    "        auc_output = auc_output.append(pd.DataFrame({\n",
    "            'partition': [partition],\n",
    "            'feature_set': [model],\n",
    "            'auc': metrics['auroc'].round(3)\n",
    "        }))\n",
    "        roc_df = metrics['roc_df']\n",
    "        roc_output = roc_output.append(pd.DataFrame({\n",
    "            'false_positive_rate': roc_df.fpr,\n",
    "            'true_positive_rate': roc_df.tpr,\n",
    "            'partition': partition,\n",
    "            'feature_set': model\n",
    "        }))\n",
    "\n",
    "(ggplot(roc_output, aes(x='false_positive_rate',\n",
    "                        y='true_positive_rate',\n",
    "                        color='feature_set',\n",
    "                        linetype='partition'))\n",
    " + geom_line(size=0.9, alpha=0.6)\n",
    " + labs(x='false positive rate', y='true positive rate')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(auc_output,\n",
    "               values='auc',\n",
    "               index='partition',\n",
    "               columns='feature_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the classifier coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pipelines = {\n",
    "    model: pipeline.best_estimator_\n",
    "    for model, pipeline in cv_pipelines.items()\n",
    "}\n",
    "final_classifiers = {\n",
    "    model: pipeline.named_steps['classify']\n",
    "    for model, pipeline in final_pipelines.items()\n",
    "}\n",
    "\n",
    "coef_df = pd.concat([\n",
    "    get_model_coefficients(classifier, model, covariate_df.columns)\n",
    "    for model, classifier in final_classifiers.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Signs of the coefficients by model\n",
    "pd.crosstab(coef_df.feature_set, np.sign(coef_df.weight).rename('coefficient_sign'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top coefficients for covariates model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_df.query(\"feature_set == 'full'\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top coefficients for individual _genes_ for full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_for_full = (\n",
    "    final_pipelines['full']\n",
    "    .named_steps['features']\n",
    "    .get_params()['expressions__pca']\n",
    "    )\n",
    "classifier_for_full = (\n",
    "    final_pipelines['full']\n",
    "    .named_steps['classify']\n",
    "    )\n",
    "gene_coefficients_for_full = get_genes_coefficients(\n",
    "    pca_object=pca_for_full,\n",
    "    classifier_object=classifier_for_full,\n",
    "    expression_df=expression_df,\n",
    "    expression_genes_df=expression_genes_df,\n",
    "    num_covariates=len(covariate_df.columns)\n",
    "    )\n",
    "gene_coefficients_for_full.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top coefficients for individual _genes_ for expressions model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_for_expression = (\n",
    "    final_pipelines['expressions']\n",
    "    .named_steps['features']\n",
    "    .get_params()['expressions__pca']\n",
    "    )\n",
    "classifier_for_expression = (\n",
    "    final_pipelines['expressions']\n",
    "    .named_steps['classify']\n",
    "    )\n",
    "gene_coefficients_for_expression = get_genes_coefficients(\n",
    "    pca_object=pca_for_expression,\n",
    "    classifier_object=classifier_for_expression,\n",
    "    expression_df=expression_df,\n",
    "    expression_genes_df=expression_genes_df\n",
    "    )\n",
    "gene_coefficients_for_expression.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame()\n",
    "for model, pipeline in final_pipelines.items():\n",
    "    df = pd.DataFrame.from_items([\n",
    "        ('feature_set', model),\n",
    "        ('sample_id', X.index),\n",
    "        ('test_set', X.index.isin(X_test.index).astype(int)),\n",
    "        ('status', y),\n",
    "        ('decision_function', pipeline.decision_function(X)),\n",
    "        ('probability', pipeline.predict_proba(X)[:, 1])\n",
    "    ])    \n",
    "    predict_df = predict_df.append(df)\n",
    "\n",
    "predict_df['probability_str'] = predict_df['probability'].apply('{:.1%}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top predictions amongst negatives (potential hidden responders to a targeted cancer therapy)\n",
    "(predict_df\n",
    "    .sort_values('decision_function', ascending=False)\n",
    "    .query(\"status == 0 and feature_set == 'full'\")\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_df['status_'] = predict_df['status'].map(\n",
    "    lambda x: 'negative' if x == 0 else 'positive')\n",
    "\n",
    "(ggplot(predict_df, aes(x='probability', \n",
    "                        y='density',\n",
    "                        fill='status_'))\n",
    " + geom_density(alpha=0.6)\n",
    " + facet_wrap('~feature_set', ncol=1)\n",
    " + labs(x='probability', y='')\n",
    " + guides(fill=guide_legend(title=\"\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
